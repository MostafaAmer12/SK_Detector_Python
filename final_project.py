# -*- coding: utf-8 -*-
"""Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VvYcKFg70Zk8CjfBC9JQxVREXVbf2U5P
"""

#@title Mounting Drive
from google.colab import drive
drive.mount('/content/drive')

#@title Constructing VGG Model
from tensorflow.keras import layers
from tensorflow.keras import models
import keras

# Defining Model
model=models.Sequential()

# Block 1
model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation="relu",input_shape=(224,224,3)))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Normalization())

# Block 2
model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation="relu"))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Normalization())

# Block 3
model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation="relu"))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Normalization())

# Block 4
model.add(layers.Conv2D(filters=256, kernel_size=(3, 3), activation="relu"))
model.add(layers.MaxPooling2D(pool_size=(2, 2)))
model.add(layers.Normalization())

# Fully Connected Layer
model.add(layers.Flatten())
model.add(layers.Dense(512, activation="relu"))

# Output Layer
model.add(layers.Dense(3, activation="softmax"))

#@title Summarizing Model
model.summary()

#@title Compiling Model
from tensorflow.keras import optimizers
opt = optimizers.Adam()

model.compile(
    optimizer=opt,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

#@title Plotting Model
from tensorflow.keras.utils import plot_model
plot_model(model)

# @title Paths For Our Data
import os,shutil

# Setting Paths to the Directory
test_dataset_dir='/content/drive/MyDrive/Version 2, erythrocytesIDB 2021/Version 2, erythrocytesIDB 2021/erythrocytesIDB1/Test'
train_dataset_dir='/content/drive/MyDrive/Version 2, erythrocytesIDB 2021/Version 2, erythrocytesIDB 2021/erythrocytesIDB1/Train/'
validation_dataset_dir='/content/drive/MyDrive/Version 2, erythrocytesIDB 2021/Version 2, erythrocytesIDB 2021/erythrocytesIDB1/Validation/'

# Path of original dataset
base_dir='/content/drive/MyDrive/Version 2, erythrocytesIDB 2021/'
try:
  os.mkdir(base_dir)
except:
  pass

######################################################################
# Train, validation and test split
# Directories for training data
train_dir=os.path.join(base_dir,'train')
try:
  os.mkdir(train_dir)
except:
  pass

# Directories for validating data
validation_dir=os.path.join(base_dir,'validation')
try:
  os.mkdir(validation_dir)
except:
  pass

# Directories for testing data
test_dir=os.path.join(base_dir,'test')
try:
  os.mkdir(test_dir)
except:
  pass

# @title Organizing Data Folders
import os,shutil
import cv2
import numpy as np


# X_train = []
# y_train = []
# X_test = []
# y_test = []

image_size=224

# labels = ['circular','elongated','others']

# Splitting Train data into 3 types
# Directory for training circular images
train_circular_dir=os.path.join(train_dir,'circular')
try:
  os.mkdir(train_circular_dir)
except:
  pass

# Directory for training elongated images
train_elongated_dir=os.path.join(train_dir,'elongated')
try:
  os.mkdir(train_elongated_dir)
except:
  pass

# Directory for training other images
train_other_dir=os.path.join(train_dir,'other')
try:
  os.mkdir(train_other_dir)
except:
  pass

######################################################################
# Splitting Validation data into 3 types
# Directory for validation circular images
validation_circular_dir=os.path.join(validation_dir,'circular')
try:
  os.mkdir(validation_circular_dir)
except:
  pass

# Directory for validation elongated images
validation_elongated_dir=os.path.join(validation_dir,'elongated')
try:
  os.mkdir(validation_elongated_dir)
except:
  pass

# Directory for validation other images
validation_other_dir=os.path.join(validation_dir,'other')
try:
  os.mkdir(validation_other_dir)
except:
  pass

######################################################################
# Splitting Test data into 3 types
# Directory for test circular images
test_circular_dir=os.path.join(test_dir,'circular')
try:
  os.mkdir(test_circular_dir)
except:
  pass

# Directory for test elongated images
test_elongated_dir=os.path.join(test_dir,'elongated')
try:
  os.mkdir(test_elongated_dir)
except:
  pass

# Directory for test other images
test_other_dir=os.path.join(test_dir,'other')
try:
  os.mkdir(test_other_dir)
except:
  pass

######################################################################
# Copying to train_circular_dir
fnames=['c({}).jpg'.format(i) for i in range(1,203)]
for fnames in fnames:
  src=os.path.join(train_dataset_dir,'circular',fnames)
  dst=os.path.join(train_circular_dir,fnames)
  shutil.copyfile(src,dst)
  # y_train.append(0)

# Copying to validation_circular_dir
fnames=['c({}).jpg'.format(i) for i in range(1,112)]
for fnames in fnames:
  src=os.path.join(validation_dataset_dir,'circular',fnames)
  dst=os.path.join(validation_circular_dir,fnames)
  shutil.copyfile(src,dst)

# Copying to test_circular_dir
fnames=['c({}).jpg'.format(i) for i in range(1,92)]
for fnames in fnames:
  src=os.path.join(test_dataset_dir,'circular',fnames)
  dst=os.path.join(test_circular_dir,fnames)
  shutil.copyfile(src,dst)
  # y_test.append(0)

######################################################################
# Copying to train_elongated_dir
fnames=['e({}).jpg'.format(i) for i in range(1,212)]
for fnames in fnames:
  src=os.path.join(train_dataset_dir,'elongated',fnames)
  dst=os.path.join(train_elongated_dir,fnames)
  shutil.copyfile(src,dst)
  # y_train.append(1)

# Copying to validation_elongated_dir
fnames=['e({}).jpg'.format(i) for i in range(1,121)]
for fnames in fnames:
  src=os.path.join(validation_dataset_dir,'elongated',fnames)
  dst=os.path.join(validation_elongated_dir,fnames)
  shutil.copyfile(src,dst)

# Copying to test_elongated_dir
fnames=['e({}).jpg'.format(i) for i in range(1,91)]
for fnames in fnames:
  src=os.path.join(test_dataset_dir,'elongated',fnames)
  dst=os.path.join(test_elongated_dir,fnames)
  shutil.copyfile(src,dst)
  # y_test.append(1)

######################################################################
# Copying to train_other_dir
fnames=['o({}).jpg'.format(i) for i in range(1,213)]
for fnames in fnames:
  src=os.path.join(train_dataset_dir,'other',fnames)
  dst=os.path.join(train_other_dir,fnames)
  shutil.copyfile(src,dst)
  # X_train.append(src)
  # y_train.append(2)

# Copying to validation_other_dir
fnames=['o({}).jpg'.format(i) for i in range(1,109)]
for fnames in fnames:
  src=os.path.join(validation_dataset_dir,'other',fnames)
  dst=os.path.join(validation_other_dir,fnames)
  shutil.copyfile(src,dst)

# Copying to test_other_dir
fnames=['o({}).jpg'.format(i) for i in range(1,104)]
for fnames in fnames:
  src=os.path.join(test_dataset_dir,'other',fnames)
  dst=os.path.join(test_other_dir,fnames)
  shutil.copyfile(src,dst)
  # y_test.append(2)

# X_train = np.array(X_train)
# y_train = np.array(y_train)
# X_test = np.array(X_test)
# y_test = np.array(y_test)

#@title Loading and Preprocessing Data
from tensorflow.keras.preprocessing.image import ImageDataGenerator
img_width=224
img_height=224
batchSize=20

# Scaling Image
train_datagen = ImageDataGenerator(
    rescale=1./255,
    )
val_datagen = ImageDataGenerator(
    rescale=1./255
    )
test_datagen = ImageDataGenerator(
    rescale=1./255
    )

# Loading train Data
train_generator = train_datagen.flow_from_directory(
    train_dir,
    batch_size=batchSize,
    class_mode='categorical',
    shuffle=True,
    target_size=(img_width, img_height),
)

# Loading Validating Data
validation_generator = val_datagen.flow_from_directory(
    validation_dir,
    batch_size=batchSize,
    class_mode='categorical',
    shuffle=True,
    target_size=(img_width, img_height)
)

# Loading Testing Data
test_generator = test_datagen.flow_from_directory(
    test_dir,
    batch_size=batchSize,
    class_mode='categorical',
    shuffle=False,
    target_size=(img_width, img_height)
)

#@title y_train ang y_test shape
# y_train.shape,y_test.shape

#@title Performing Encoding on the labels after changing into numerical values
# import tensorflow as tf

# y_train_new = []
# for i in y_train:
#     y_train_new.append(labels[i])
# y_train = y_train_new
# print(y_train)

# y_test_new = []
# for i in y_test:
#     y_test_new.append(labels[i])
# y_test = y_test_new
# print(y_test)

#@title Monitor and Control Training
from keras import callbacks

earlyStop = callbacks.EarlyStopping(
    monitor='val_accuracy',
    min_delta=0,
    patience=15,
    verbose=1,
    mode='auto'
)

#@title Fitting Model
history= model.fit(
    train_generator,
    steps_per_epoch=10,
    epochs=100,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples//batchSize,
    callbacks=[earlyStop]
)

#@title Saving Model
model.save('/content/drive/MyDrive/vgg16.h5')

#@title Loading Model
from tensorflow.keras.models import load_model
saved_model=load_model('/content/drive/MyDrive/vgg16.h5')

#@title Importing Testing Images
import cv2
import matplotlib.pyplot as plt
import numpy as np

test_pred = model.predict(test_generator)
test_pred = np.argmax(test_pred,axis=1)
print(test_pred)

print (test_generator.classes)

# @title Classification Report
from sklearn.metrics import classification_report
print(classification_report(test_generator.classes,test_pred))

#@title Importing and Showing Image
import cv2
import matplotlib.pyplot as plt

img=cv2.imread('/content/drive/MyDrive/source.jpg')
img = cv2.resize(img,(224,224))
plt.imshow(img)

#@title Predicting Image
pred=saved_model.predict(img.reshape(1,224,224,3))

print(pred)

#@title Extract the Largest Value
import numpy as np

x=np.argmax(pred)
print(x)

#@title Display Results

if x == 0:
    print("circular")
elif x == 1:
    print("elongated")
else:
    print("other")

#@title Visualize Model Accuracy and Loss
import matplotlib.pyplot as plt

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']
epochs=range(len(acc))

# Plot training and validation acccuracy
plt.plot(epochs,acc,'bo',label='Training acc')
plt.plot(epochs,val_acc,'b',label='Validation acc')
plt.title("Model Accuracy")
plt.legend()
plt.figure()

# Plot training and validation loss
plt.plot(epochs,loss,'bo',label='Training loss')
plt.plot(epochs,val_loss,'b',label='Validation loss')
plt.title("Model Loss")
plt.legend()
plt.figure()
plt.show()

#@title Confusion Matrix Heatmap
import seaborn as sns
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay

c_matrix = confusion_matrix(test_generator.classes,test_pred)
cm_display= ConfusionMatrixDisplay(confusion_matrix=c_matrix,display_labels=test_generator.class_indices)
cm_display.plot(cmap=plt.cm.Blues)
plt.show()

#@title Convert the h5 model into tflite

from tensorflow import lite
converter= lite.TFLiteConverter.from_keras_model(model=saved_model)
tflite_model=converter.convert()
open('/content/drive/MyDrive/vgg16.tflite','wb').write(tflite_model)